{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RxplubDqXjDh"
   },
   "source": [
    "# Optimizers in Action\n",
    "Exploring Optimizers one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "79Z98RGPuEXN",
    "outputId": "a804ab0b-78c8-4472-b7b9-1a4d4ede37bb"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40d4h7VnXhDl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# 3D plotting\n",
    "from mpl_toolkits import mplot3d\n",
    "# animation\n",
    "from matplotlib import animation\n",
    "from matplotlib.gridspec import GridSpec\n",
    "plt.rc('animation', html='html5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UkxtqTHvx8cq"
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O5d9Ss6396B3"
   },
   "source": [
    "## Linear Regression\n",
    "A linear regression problem is very easy to plot the parameters as well as the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LI4RiYIvUyOx"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJQMc7El7orw"
   },
   "outputs": [],
   "source": [
    "size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "MkZXXAt77wTO",
    "outputId": "3cac8a26-5036-40f7-a156-ef009fa44f46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5250,  1.0000],\n",
       "        [ 0.5945,  1.0000],\n",
       "        [ 0.1397,  1.0000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(size, 2)\n",
    "X[:, 0].uniform_(-1., 1)\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nxm-SZBr7yT8"
   },
   "outputs": [],
   "source": [
    "W     = torch.tensor([5., 3])  # weight and bias\n",
    "error = torch.rand(size)        # some random error per yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yG9UIVq8vuP"
   },
   "outputs": [],
   "source": [
    "y_hat = X @ W\n",
    "y = y_hat + error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "QOkHpbDy82HG",
    "outputId": "afe6fb5b-7ce0-4f36-86a3-2fbdff7f8764"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb2f9a32a00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], y, label='y');\n",
    "plt.scatter(X[:,0], y_hat, label='y_hat');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_j5Np-l-A2r"
   },
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNZVBVTFAYIG"
   },
   "source": [
    "Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TpeWodnz9D6u"
   },
   "outputs": [],
   "source": [
    "def mse(y, y_hat): return ((y-y_hat)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0KArpNp-HQL"
   },
   "source": [
    "Mean Square Root Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kzknmKBb-GKX"
   },
   "outputs": [],
   "source": [
    "def msre(y, y_hat): return ((y-y_hat)**2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpceseEDAa_b"
   },
   "source": [
    "Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XG2Nk_dWAQcb"
   },
   "outputs": [],
   "source": [
    "def mae(y, y_hat): return ((y-y_hat).abs()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kRnTUA5iAHs6",
    "outputId": "6c30c938-80cf-429b-e937-e26a017982bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3220), tensor(0.4756))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y, X @ W), mae(y, X @ W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovZrl2QbAE5R"
   },
   "source": [
    "#### Visualisation\n",
    "Let's visualize the loss function landscape as a function of the parameters (i.e. weight and bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07URD_JP_AB4"
   },
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def loss_func(w1, w2, loss=mse):\n",
    "    W = torch.Tensor([w1, w2])\n",
    "    y_hat = X @ W\n",
    "    return loss(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uiEt-1KvE-F1"
   },
   "source": [
    "A helper function to generate samples for the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pg90905gCg1z"
   },
   "outputs": [],
   "source": [
    "def grid_samples(offset=20, size=100):\n",
    "    range1 = np.linspace(-offset, offset, size)\n",
    "    range2 = np.linspace(-offset, offset, size)\n",
    "    return np.meshgrid(range1, range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "msoYhTrqDGWc",
    "outputId": "d5fe4610-c39d-4492-fb5b-c5a27cbf5251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples for wights have a shape of [(100, 100), (100, 100)]\n"
     ]
    }
   ],
   "source": [
    "weights = grid_samples(); print(f'Samples for wights have a shape of {[w.shape for w in weights]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZs7CBy1-1I7"
   },
   "outputs": [],
   "source": [
    "def plot_loss_funcs(weights, samples, fcts, titles, view=(20, 50)):\n",
    "    num_fcts = len(fcts)\n",
    "    fig = plt.figure(figsize=(7 * num_fcts,7))\n",
    "    for i in range(num_fcts):\n",
    "        loss = loss_func(*weights, loss=fcts[i])\n",
    "        ax = fig.add_subplot(1, num_fcts, i+1, projection='3d')\n",
    "        ax.plot_surface(*samples, loss, cmap='viridis', alpha=0.8)\n",
    "        ax.set_xlabel('w0'); ax.set_ylabel('w1'); ax.set_zlabel('Loss')\n",
    "        ax.set_title(titles[i])\n",
    "        ax.view_init(*view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "icN2tBQm_U_W",
    "outputId": "2ca631ab-f11c-4d8a-e705-4bdd2cb89209"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_loss_funcs(weights, \u001b[43msamples\u001b[49m, fcts\u001b[38;5;241m=\u001b[39m[mse, msre, mae], titles\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean Square Error loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean Square Root Error loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean Absolute Error loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss_funcs(weights, samples, fcts=[mse, msre, mae], titles=['Mean Square Error loss', 'Mean Square Root Error loss', 'Mean Absolute Error loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rmWJO1dBVBWc"
   },
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dq1TCtpM8Vya"
   },
   "source": [
    "A simple optimizer that keep tracks of parameters, hyper parameters, and a collection of optimization steps which are supposed to contains the logic for updating parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYC3DC_3knyi"
   },
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, steppers, **defaults):\n",
    "        # might be a generator\n",
    "        self.param_groups = list(params)\n",
    "        # ensure params is a list of lists\n",
    "        if not isinstance(self.param_groups[0], list): self.param_groups = [self.param_groups]\n",
    "        self.hypers = [{**defaults} for p in self.param_groups]\n",
    "        self.steppers = steppers\n",
    "        \n",
    "    def grad_params(self):\n",
    "        for pg,hyper in zip(self.param_groups,self.hypers):\n",
    "            for p in pg:\n",
    "                if p.grad is None: continue\n",
    "                yield (p,hyper)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p, hyperp in self.grad_params():\n",
    "            p.grad.detach_()\n",
    "            p.grad.zero_()\n",
    "            \n",
    "    def step(self):\n",
    "        for p, hyperp in self.grad_params():\n",
    "            for step in self.steppers: p = step(p, **hyperp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pdVIRFE18SXs"
   },
   "source": [
    "An optimizer that keep tracks of parameters and their statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2DoF0CA8N0_"
   },
   "outputs": [],
   "source": [
    "class StatefulOptimizer(Optimizer):\n",
    "    def __init__(self, parms, steppers, stats=None, **defaults):\n",
    "        super().__init__(parms, steppers, **defaults)\n",
    "        self.stats = stats\n",
    "        self.state = {}\n",
    "        \n",
    "    def step(self):\n",
    "        for p, hyperp in self.grad_params():\n",
    "            if p not in self.state:\n",
    "                self.state[p] = {}\n",
    "                for s in self.stats:\n",
    "                    for k,v in s.init_state(p).items():\n",
    "                        self.state[p][k] = v\n",
    "            state = self.state[p]\n",
    "            for stat in self.stats: state = stat.update(p, state, **hyperp)\n",
    "            for step in self.steppers: p = step(p, **state, **hyperp)\n",
    "            self.state[p] = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGgyNbkSC-x9"
   },
   "source": [
    "A generic class for calculating statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9PCI8Hb5Cmu_"
   },
   "outputs": [],
   "source": [
    "class Stat():\n",
    "    def init_state(self, p): raise NotImplementedError\n",
    "    def update(self, p, state, **kwargs): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2xpk-9o8WQyU"
   },
   "source": [
    "Moving Average of Gradadients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vplCFN9sVD99"
   },
   "outputs": [],
   "source": [
    "class AverageGrad(Stat):\n",
    "    def __init__(self, dampening=False):\n",
    "        self.dampening = dampening\n",
    "    def init_state(self, p):\n",
    "        return {'grad_avg': torch.zeros_like(p.grad.data)}\n",
    "    def update(self, p, state, mom, **kwargs):\n",
    "        state['mom_damp'] = 1-mom if self.dampening else 1.\n",
    "        state['grad_avg'].mul_(mom).add_(state['mom_damp'], p.grad.data)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXccPBMMWeOt"
   },
   "source": [
    "Moving Average of Gradients Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RsMq38EYWoU4"
   },
   "outputs": [],
   "source": [
    "class AverageSqrGrad(Stat):\n",
    "    def __init__(self, dampening=False):\n",
    "        self.dampening = dampening\n",
    "    def init_state(self, p):\n",
    "        return {'sqr_avg': torch.zeros_like(p.grad.data)}\n",
    "    def update(self, p, state, sqr_mom, **kwargs):\n",
    "        state['sqr_damp'] = 1-sqr_mom if self.dampening else 1.\n",
    "        state['sqr_avg'].mul_(sqr_mom).addcmul_(state['sqr_damp'], p.grad.data, p.grad.data)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsl_GUttXk-5"
   },
   "source": [
    "Number of the steps so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMIRPwNeXknh"
   },
   "outputs": [],
   "source": [
    "class StepCount(Stat):\n",
    "    def init_state(self, p):\n",
    "        return {'step': 0}\n",
    "    def update(self, p, state, **kwargs):\n",
    "        state['step'] += 1\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dfQf4mD0sWJ"
   },
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsXoVUi-tYmH"
   },
   "outputs": [],
   "source": [
    "def sgd_step(p, lr, **kwargs):\n",
    "    p.data.add_(-lr, p.grad.data)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1WenT8i2jaM"
   },
   "source": [
    "#### Weight Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lcAd-aZp23Ro"
   },
   "source": [
    "Weight decay is subtracting $lr*wd*weight$ from the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mqmxrne2hwX"
   },
   "outputs": [],
   "source": [
    "def weight_decay(p, lr, wd, **kwargs):\n",
    "    p.data.mul_(1 - lr*wd)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gruR0w5z2t2v"
   },
   "source": [
    "L2 regularization is adding $wd*weight$ to the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRJfEKSt28tC"
   },
   "outputs": [],
   "source": [
    "def l2_reg(p, lr, wd, **kwargs):\n",
    "    p.grad.data.add_(wd, p.data)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSXzWb7g5KO1"
   },
   "source": [
    "#### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PyoDs_Vq5k9_"
   },
   "outputs": [],
   "source": [
    "def momentum_step(p, lr, grad_avg, **kwargs):\n",
    "    p.data.add_(-lr, grad_avg)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNw3PJj8DGpP"
   },
   "source": [
    "A specialization for **Stat** class responsible for calculating averages\n",
    "##### Regular Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j4scOE4nDF6r"
   },
   "outputs": [],
   "source": [
    "class AverageGrad1(AverageGrad):\n",
    "    def update(self, p, state, mom, **kwargs):\n",
    "        state['grad_avg'].mul_(mom).add_(p.grad.data)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWD16h9HQMAc"
   },
   "source": [
    "##### Exponentially Weighted Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FoRqMvIwQK5m"
   },
   "outputs": [],
   "source": [
    "class AverageGrad2(AverageGrad):\n",
    "    def update(self, p, state, mom, **kwargs):\n",
    "        state['grad_avg'].mul_(mom).add_(1-mom, p.grad.data)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAHzfyiDQezg"
   },
   "source": [
    "##### Debiased Exponentially Weighted Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cx-qezbFQeT3"
   },
   "outputs": [],
   "source": [
    "class AverageGrad3(AverageGrad):\n",
    "    def update(self, p, state, mom, **kwargs):\n",
    "        ith = state['step'] if 'step' in state else None\n",
    "        state['grad_avg'].mul_(mom).add_(1-mom, p.grad.data).mul_(1 / (1-mom**(ith+1)))\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3Vw4xC3X8vc"
   },
   "source": [
    "#### ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFyINISAX-to"
   },
   "outputs": [],
   "source": [
    "def debias(mom, damp, step): return damp * (1 - mom**step) / (1-mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9CknLVTYIlb"
   },
   "outputs": [],
   "source": [
    "def adam_step(p, lr, mom, mom_damp, step, sqr_mom, sqr_damp, grad_avg, sqr_avg, eps, **kwargs):\n",
    "    debias1 = debias(mom, mom_damp, step)\n",
    "    debias2 = debias(sqr_mom, sqr_damp, step)\n",
    "    p.data.addcdiv_(-lr / debias1, grad_avg, (sqr_avg/debias2).sqrt() + eps)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FVckDZjSbAQ5"
   },
   "source": [
    "#### LAMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Fex6HG7a_12"
   },
   "outputs": [],
   "source": [
    "def lamb_step(p, lr, mom, mom_damp, step, sqr_mom, sqr_damp, grad_avg, sqr_avg, eps, wd, **kwargs):\n",
    "    debias1 = debias(mom, mom_damp, step)\n",
    "    debias2 = debias(sqr_mom, sqr_damp, step)\n",
    "    r1 = p.data.pow(2).mean().sqrt()\n",
    "    step = (grad_avg/debias1) / ((sqr_avg/debias2).sqrt()+eps) + wd*p.data\n",
    "    r2 = step.pow(2).mean().sqrt()\n",
    "    p.data.add_(-lr * min(r1/r2, 10), step)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GpgmwQHp0yKF"
   },
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MUk_DgML1cXY"
   },
   "source": [
    "A plain old training loop, eventually refactor this into (begin/end epoch), add some param scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41dNN2B9K21P"
   },
   "outputs": [],
   "source": [
    "def fit(X, y, epochs=10, w0=[-1, 0], loss_func=mse, opt_func=None):\n",
    "    loss_history, weights_hisotry = [], []\n",
    "    W = torch.tensor(w0, requires_grad=True)\n",
    "    opt = opt_func([W])\n",
    "    for t in range(epochs):\n",
    "        # forward\n",
    "        y_hat = X @ W\n",
    "        loss = loss_func(y, y_hat)\n",
    "        weights = W.data.clone()\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        # record\n",
    "        loss_history.append(loss.item())\n",
    "        weights_hisotry.append(weights)\n",
    "    weights_hisotry = torch.stack(weights_hisotry)\n",
    "    return weights_hisotry, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2d7tzjgnS09E"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "# hyper parameters\n",
    "hyperparams = (dict([('lr', 0.1), ('wd', 0.1), ('mom', 0.9), ('sqr_mom', 0.99), ('eps', 1e-6)]))\n",
    "\n",
    "# initial parameters (weights)\n",
    "initial_weights = [-10., -20.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8QhzzbfVMQC"
   },
   "outputs": [],
   "source": [
    "# SGD\n",
    "sgd_opt = partial(Optimizer, steppers=[sgd_step], **(hyperparams))\n",
    "wgts1, losses1 = fit(X, y, epochs=epochs, w0=initial_weights, loss_func=msre, opt_func=sgd_opt)\n",
    "\n",
    "# SGD + Weight Deay\n",
    "sgd_wd_opt = partial(Optimizer, steppers=[weight_decay, sgd_step], **(hyperparams))\n",
    "wgts2, losses2 = fit(X, y, epochs=epochs, w0=initial_weights, loss_func=msre, opt_func=sgd_wd_opt)\n",
    "\n",
    "# SGD + Weight Deay + Momentum\n",
    "sgd_mom_opt_1 = partial(StatefulOptimizer, steppers=[momentum_step,weight_decay], stats=[AverageGrad1()], **(hyperparams))\n",
    "wgts3, losses3 = fit(X, y, epochs=epochs, w0=initial_weights, loss_func=msre, opt_func=sgd_mom_opt_1)\n",
    "\n",
    "# SGD + Weight Deay + Momentum (EWMA)\n",
    "sgd_mom_opt_2 = partial(StatefulOptimizer, steppers=[momentum_step,weight_decay], stats=[AverageGrad2()], **(hyperparams))\n",
    "wgts4, losses4 = fit(X, y, epochs=epochs, w0=initial_weights, loss_func=msre, opt_func=sgd_mom_opt_2)\n",
    "\n",
    "# SGD + Weight Deay + Momentum (Debiased EWMA)\n",
    "sgd_mom_opt_3 = partial(StatefulOptimizer, steppers=[momentum_step,weight_decay], stats=[AverageGrad3(), StepCount()], **(hyperparams))\n",
    "wgts5, losses5 = fit(X, y, epochs=epochs, w0=initial_weights, loss_func=msre, opt_func=sgd_mom_opt_3)\n",
    "\n",
    "# ADAM\n",
    "adam_opt = partial(StatefulOptimizer, steppers=[adam_step, weight_decay], stats=[AverageGrad(dampening=True), AverageSqrGrad(), StepCount()], **(hyperparams))\n",
    "wgts6, losses6 = fit(X, y, epochs=epochs, w0=initial_weights, loss_func=msre, opt_func=adam_opt)\n",
    "\n",
    "# LAMB\n",
    "lamb_opt = partial(StatefulOptimizer, steppers=[lamb_step], stats=[AverageGrad(dampening=True), AverageSqrGrad(), StepCount()], **(hyperparams))\n",
    "wgts7, losses7 = fit(X, y, epochs=epochs, w0=initial_weights, loss_func=msre, opt_func=adam_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "0h6lYZ0DVPx6",
    "outputId": "6594e7b0-aa96-4de9-da70-40cd56c946f8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(losses1, label='sgd')\n",
    "plt.plot(losses2, label='sgd+wd')\n",
    "plt.plot(losses3, label='sgd+wd+mom')\n",
    "plt.plot(losses4, label='sgd+wd+mom(ewma)')\n",
    "#plt.plot(losses5, label='sgd+wd+mom(dewma)')\n",
    "plt.plot(losses6, label='adam')\n",
    "plt.plot(losses7, label='lamb')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ylRtAYbsdQ0h"
   },
   "source": [
    "## Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blK35KcGd_9M"
   },
   "outputs": [],
   "source": [
    "# input for plotting\n",
    "\n",
    "\n",
    "fcts=[mse, msre, mae]; titles=['Mean Square Error loss', 'Mean Square Root Error loss', 'Mean Absolute Error loss']\n",
    "\n",
    "i = 1\n",
    "loss_curve = loss_func(*weights, loss=fcts[i])\n",
    "\n",
    "max_loss = 30# int(loss_curve.max())\n",
    "max_weights = max(weights[0].max(), weights[1].max())\n",
    "min_weights = min(weights[0].min(), weights[1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wJkcxqaebEh2"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 8))\n",
    "gs = GridSpec(2, 2, width_ratios=[1, 2.5])\n",
    "\n",
    "# plot ground truth & model\n",
    "ax0 = fig.add_subplot(gs[0,0])\n",
    "ax0.scatter(X[:,0], y, c='orange', label='Ground truth')\n",
    "ax0.set_ylim(-1, 6)\n",
    "ax0.set_title('Ground truth & Model', fontsize=16)\n",
    "line0, = ax0.plot([], [], label='Model')\n",
    "ax0.legend(loc='lower right')\n",
    "\n",
    "# plot loss (output of the sampling)\n",
    "ax1 = fig.add_subplot(gs[:,1], projection='3d')\n",
    "ax1.set_title('Loss', fontsize=16, pad=20)\n",
    "ax1.plot_surface(*samples, loss_curve, cmap='viridis', alpha=0.8)\n",
    "# mark the optimial solution (i.e. target of the training)\n",
    "ax1.plot3D([W[0]], [W[1]], [0], c='r', marker='x', markersize=10,  label='Target', linewidth=0)\n",
    "line1, = ax1.plot3D([], [], [], c='r', marker='o', alpha=0.4, label='loss')\n",
    "ax1.set_xlabel('w0'); ax1.set_ylabel('w1'); ax1.set_zlabel('Loss')\n",
    "ax1.view_init(50, 70)\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "# plot weights & loss (output of training)\n",
    "ax2 = fig.add_subplot(gs[1,0])\n",
    "ax2.set_title('Weights & Loss', fontsize=16)\n",
    "line2, = ax2.plot([],[], label='w0')\n",
    "line3, = ax2.plot([],[], label='w1')\n",
    "ax2.set_ylim(min_weights, max_weights)\n",
    "ax2.set_xlim(0, epochs)\n",
    "ax2.set_xlabel('epochs')\n",
    "ax2.set_ylabel('weights')\n",
    "ax3 = ax2.twinx()\n",
    "line4, = ax3.plot([],[], label='loss', c='r')\n",
    "ax3.set_ylabel('loss')\n",
    "ax3.set_ybound(0, max_loss)\n",
    "\n",
    "ax2.legend((line2, line3, line4), ('w0', 'w1', 'loss'), loc='center right')\n",
    "\n",
    "title = fig.suptitle(f'lr: {lr} - Epoch: 0/{epochs}', fontsize=22)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.85)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "def animate(i):   \n",
    "    line0.set_data(X[:,0].numpy(), (X@wgts[i]).numpy())\n",
    "    line1.set_data(wgts[:i+1,0].numpy(), wgts[:i+1,1].numpy())\n",
    "    line1.set_3d_properties(losses[:i+1])\n",
    "    steps = np.arange(i+1)\n",
    "    line2.set_data(steps, wgts[:i+1, 0].numpy())\n",
    "    line3.set_data(steps, wgts[:i+1, 1].numpy())\n",
    "    line4.set_data(steps, losses[:i+1])\n",
    "    title.set_text(f'lr: {lr} - Epoch: {i+1}/{epochs}')\n",
    "    return line0, line1, line2, line3, line4, title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Bk_s-oP3S1p"
   },
   "source": [
    "### SGD + Weight Decay + Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "cpfH3TUF3SZ_",
    "outputId": "22d37083-44cd-4220-a6dd-8bf155a0e28e"
   },
   "outputs": [],
   "source": [
    "wgts = wgts3\n",
    "losses = np.array(losses3)\n",
    "\n",
    "max_weights = max(wgts[:, 0].max(), wgts[:, 1].max())\n",
    "min_weights = min(wgts[:, 0].min(), wgts[:, 1].min())\n",
    "\n",
    "print(f'Max loss is {max_loss}, Max weights {max_weights} Min weights={min_weights}')\n",
    "print(f'The solution for wights should be {W}')\n",
    "print(f'Weights and losses from training: {wgts.shape}, {losses.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "colab_type": "code",
    "id": "9kt3oyoq3ol7",
    "outputId": "d56c3bba-7825-485d-c724-4e810a55f283"
   },
   "outputs": [],
   "source": [
    "animation.FuncAnimation(fig, animate, range(epochs), interval=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diAMpIANwdC4"
   },
   "source": [
    "### LAMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "GVNvlaRnkUSs",
    "outputId": "33b7fadb-62c9-4003-deef-bd96dfbf8b25"
   },
   "outputs": [],
   "source": [
    "wgts = wgts7\n",
    "losses = np.array(losses7)\n",
    "max_loss = max(max_loss, losses.max())\n",
    "\n",
    "max_weights = max(wgts[0].max(), wgts[1].max())\n",
    "min_weights = min(wgts[0].min(), wgts[1].min())\n",
    "\n",
    "\n",
    "print(f'Max loss is {max_loss}, Max weights {max_weights} Min weights={min_weights}')\n",
    "print(f'The solution for wights should be {W}')\n",
    "print(f'Weights and losses from training: {wgts.shape}, {losses.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "colab_type": "code",
    "id": "j4fHJc-MtBB_",
    "outputId": "99b17f8b-9faf-41c9-e21c-ce199303a5f7"
   },
   "outputs": [],
   "source": [
    "animation.FuncAnimation(fig, animate, range(epochs), interval=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wYCw0Arumh10"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Optimizers in Action.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
